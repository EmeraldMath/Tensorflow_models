{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_keras_regression-customized_loss",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP80u5RYq7IbQmikqStpCQD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmeraldMath/Tensorflow_models/blob/master/tf_keras_regression_customized_loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qTaQkiL_QP3",
        "colab_type": "code",
        "outputId": "e6342e4f-d815-4a9f-f231-ee44d21276f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0\n",
            "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
            "matplotlib 3.1.3\n",
            "numpy 1.17.5\n",
            "pandas 0.25.3\n",
            "sklearn 0.22.1\n",
            "tensorflow 2.1.0\n",
            "tensorflow_core.python.keras.api._v2.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saB-LVmq_T6P",
        "colab_type": "code",
        "outputId": "42282bd9-0ef3-4169-fda5-778a12755d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "print(housing.DESCR)\n",
        "print(housing.data.shape)\n",
        "print(housing.target.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 20640\n",
            "\n",
            "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
            "\n",
            "    :Attribute Information:\n",
            "        - MedInc        median income in block\n",
            "        - HouseAge      median house age in block\n",
            "        - AveRooms      average number of rooms\n",
            "        - AveBedrms     average number of bedrooms\n",
            "        - Population    block population\n",
            "        - AveOccup      average house occupancy\n",
            "        - Latitude      house block latitude\n",
            "        - Longitude     house block longitude\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "This dataset was obtained from the StatLib repository.\n",
            "http://lib.stat.cmu.edu/datasets/\n",
            "\n",
            "The target variable is the median house value for California districts.\n",
            "\n",
            "This dataset was derived from the 1990 U.S. census, using one row per census\n",
            "block group. A block group is the smallest geographical unit for which the U.S.\n",
            "Census Bureau publishes sample data (a block group typically has a population\n",
            "of 600 to 3,000 people).\n",
            "\n",
            "It can be downloaded/loaded using the\n",
            ":func:`sklearn.datasets.fetch_california_housing` function.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
            "      Statistics and Probability Letters, 33 (1997) 291-297\n",
            "\n",
            "(20640, 8)\n",
            "(20640,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYWEvKM4JrZZ",
        "colab_type": "code",
        "outputId": "28db4d0a-961b-428a-fd0f-809a116cd49e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
        "    housing.data, housing.target, random_state = 7) #default test_size = 0.25\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    x_train_all, y_train_all, random_state = 11)\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_valid.shape, y_valid.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11610, 8) (11610,)\n",
            "(3870, 8) (3870,)\n",
            "(5160, 8) (5160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iC77xYJKYs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_valid_scaled = scaler.transform(x_valid)\n",
        "x_test_scaled = scaler.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9uaKZuuKvtf",
        "colab_type": "code",
        "outputId": "9e1b2b6e-3fc9-465e-ea1a-b69f84a454cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "def customized_mse(y_true, y_pred):\n",
        "  return tf.reduce_mean(tf.square(y_pred - y_true))\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation='relu',\n",
        "                       input_shape = x_train.shape[1:]),\n",
        "    keras.layers.Dense(1),                 \n",
        "])\n",
        "model.summary()\n",
        "model.compile(loss=customized_mse, optimizer='sgd',\n",
        "              metrics=['mean_squared_error'])\n",
        "callbacks = [keras.callbacks.EarlyStopping(\n",
        "    patience=5, min_delta = 1e-2)]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 30)                270       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 301\n",
            "Trainable params: 301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KonwzQFBMtMr",
        "colab_type": "code",
        "outputId": "0b67039f-248d-408f-f8dd-f9d2e0e70364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "history = model.fit(x_train_scaled, y_train,\n",
        "                    validation_data = (x_valid_scaled, y_valid),\n",
        "                    epochs = 100,\n",
        "                    callbacks = callbacks)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "11610/11610 [==============================] - 1s 105us/sample - loss: 0.9906 - mean_squared_error: 0.9906 - val_loss: 0.8765 - val_mean_squared_error: 0.8765\n",
            "Epoch 2/100\n",
            "11610/11610 [==============================] - 1s 59us/sample - loss: 0.9203 - mean_squared_error: 0.9203 - val_loss: 0.5114 - val_mean_squared_error: 0.5114\n",
            "Epoch 3/100\n",
            "11610/11610 [==============================] - 1s 62us/sample - loss: 0.4955 - mean_squared_error: 0.4955 - val_loss: 0.4327 - val_mean_squared_error: 0.4327\n",
            "Epoch 4/100\n",
            "11610/11610 [==============================] - 1s 61us/sample - loss: 0.4074 - mean_squared_error: 0.4074 - val_loss: 0.4099 - val_mean_squared_error: 0.4099\n",
            "Epoch 5/100\n",
            "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3920 - mean_squared_error: 0.3920 - val_loss: 0.4548 - val_mean_squared_error: 0.4548\n",
            "Epoch 6/100\n",
            "11610/11610 [==============================] - 1s 62us/sample - loss: 0.3898 - mean_squared_error: 0.3898 - val_loss: 0.3869 - val_mean_squared_error: 0.3869\n",
            "Epoch 7/100\n",
            "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3765 - mean_squared_error: 0.3765 - val_loss: 0.3822 - val_mean_squared_error: 0.3822\n",
            "Epoch 8/100\n",
            "11610/11610 [==============================] - 1s 59us/sample - loss: 0.3736 - mean_squared_error: 0.3736 - val_loss: 0.3833 - val_mean_squared_error: 0.3833\n",
            "Epoch 9/100\n",
            "11610/11610 [==============================] - 1s 59us/sample - loss: 0.3696 - mean_squared_error: 0.3697 - val_loss: 0.3774 - val_mean_squared_error: 0.3774\n",
            "Epoch 10/100\n",
            "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3660 - mean_squared_error: 0.3660 - val_loss: 0.3752 - val_mean_squared_error: 0.3752\n",
            "Epoch 11/100\n",
            "11610/11610 [==============================] - 1s 59us/sample - loss: 0.3628 - mean_squared_error: 0.3628 - val_loss: 0.3729 - val_mean_squared_error: 0.3729\n",
            "Epoch 12/100\n",
            "11610/11610 [==============================] - 1s 59us/sample - loss: 0.3630 - mean_squared_error: 0.3630 - val_loss: 0.3726 - val_mean_squared_error: 0.3726\n",
            "Epoch 13/100\n",
            "11610/11610 [==============================] - 1s 59us/sample - loss: 0.3642 - mean_squared_error: 0.3642 - val_loss: 0.3743 - val_mean_squared_error: 0.3743\n",
            "Epoch 14/100\n",
            "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3562 - mean_squared_error: 0.3562 - val_loss: 0.3671 - val_mean_squared_error: 0.3671\n",
            "Epoch 15/100\n",
            "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3540 - mean_squared_error: 0.3540 - val_loss: 0.3658 - val_mean_squared_error: 0.3658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwKk-GsPNIvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_learning_curves(history):\n",
        "  pd.DataFrame(history.history).plot(figsize = (8,5))\n",
        "  plt.grid(True)\n",
        "  plt.gca().set_ylim(0,1)\n",
        "  plt.show()\n",
        "plot_learning_curves(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF3UQ95bNkyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(x_test_scaled, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN5M0IJHOQNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh9WL_ThxCBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir callbacks"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}