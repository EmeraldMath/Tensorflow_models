{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_keras_regression_model-hp-search-sklearn",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNHxAZIPHH6cSPVcK3zVwKY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmeraldMath/Tensorflow_models/blob/master/tf_keras_regression_model_hp_search_sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qTaQkiL_QP3",
        "colab_type": "code",
        "outputId": "ebeee83b-606a-4e7f-bec8-580227054f32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0\n",
            "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
            "matplotlib 3.1.3\n",
            "numpy 1.17.5\n",
            "pandas 0.25.3\n",
            "sklearn 0.22.1\n",
            "tensorflow 2.1.0\n",
            "tensorflow_core.python.keras.api._v2.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saB-LVmq_T6P",
        "colab_type": "code",
        "outputId": "0d4fc135-3681-4249-d790-d6afa2d63cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "print(housing.DESCR)\n",
        "print(housing.data.shape)\n",
        "print(housing.target.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 20640\n",
            "\n",
            "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
            "\n",
            "    :Attribute Information:\n",
            "        - MedInc        median income in block\n",
            "        - HouseAge      median house age in block\n",
            "        - AveRooms      average number of rooms\n",
            "        - AveBedrms     average number of bedrooms\n",
            "        - Population    block population\n",
            "        - AveOccup      average house occupancy\n",
            "        - Latitude      house block latitude\n",
            "        - Longitude     house block longitude\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "This dataset was obtained from the StatLib repository.\n",
            "http://lib.stat.cmu.edu/datasets/\n",
            "\n",
            "The target variable is the median house value for California districts.\n",
            "\n",
            "This dataset was derived from the 1990 U.S. census, using one row per census\n",
            "block group. A block group is the smallest geographical unit for which the U.S.\n",
            "Census Bureau publishes sample data (a block group typically has a population\n",
            "of 600 to 3,000 people).\n",
            "\n",
            "It can be downloaded/loaded using the\n",
            ":func:`sklearn.datasets.fetch_california_housing` function.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
            "      Statistics and Probability Letters, 33 (1997) 291-297\n",
            "\n",
            "(20640, 8)\n",
            "(20640,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYWEvKM4JrZZ",
        "colab_type": "code",
        "outputId": "7cf6ee41-9b56-4be5-ebed-5d4f6aaa2a78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
        "    housing.data, housing.target, random_state = 7) #default test_size = 0.25\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    x_train_all, y_train_all, random_state = 11)\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_valid.shape, y_valid.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11610, 8) (11610,)\n",
            "(3870, 8) (3870,)\n",
            "(5160, 8) (5160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iC77xYJKYs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_valid_scaled = scaler.transform(x_valid)\n",
        "x_test_scaled = scaler.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9uaKZuuKvtf",
        "colab_type": "code",
        "outputId": "88c341c3-0f7f-4fca-c621-09e7e69fd43b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# RandomizedSearchCV\n",
        "# 1. convert keras model into sklearn model\n",
        "# 2. define the set of parameters\n",
        "# 3. search hyperparameters with randomized search\n",
        "\n",
        "def build_model(hidden_layers = 1,\n",
        "                layer_size = 30,\n",
        "                learning_rate = 3e-3):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Dense(30, activation='relu',\n",
        "                          input_shape = x_train.shape[1:]))\n",
        "    # add fully connected hidden layers with the input size of previous layer\n",
        "    for _ in range(hidden_layers - 1):\n",
        "        model.add(keras.layers.Dense(layer_size,\n",
        "                                     activation='relu'))\n",
        "    model.add(keras.layers.Dense(1)) \n",
        "    optimizer = keras.optimizers.SGD(learning_rate)\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "sklearn_model = keras.wrappers.scikit_learn.KerasRegressor(build_fn = build_model)\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=5, min_delta = 1e-2)]\n",
        "history = sklearn_model.fit(x_train_scaled, y_train,\n",
        "                            epochs = 100,\n",
        "                            validation_data = (x_valid_scaled, y_valid),\n",
        "                            callbacks = callbacks)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "11610/11610 [==============================] - 3s 262us/sample - loss: 1.2097 - val_loss: 0.7051\n",
            "Epoch 2/100\n",
            "11610/11610 [==============================] - 1s 90us/sample - loss: 0.6091 - val_loss: 0.6235\n",
            "Epoch 3/100\n",
            "11610/11610 [==============================] - 1s 85us/sample - loss: 0.5451 - val_loss: 0.5620\n",
            "Epoch 4/100\n",
            "11610/11610 [==============================] - 1s 92us/sample - loss: 0.5204 - val_loss: 0.5330\n",
            "Epoch 5/100\n",
            "11610/11610 [==============================] - 1s 94us/sample - loss: 0.5235 - val_loss: 0.5184\n",
            "Epoch 6/100\n",
            "11610/11610 [==============================] - 1s 98us/sample - loss: 0.4990 - val_loss: 0.4945\n",
            "Epoch 7/100\n",
            "11610/11610 [==============================] - 1s 94us/sample - loss: 0.4710 - val_loss: 0.4840\n",
            "Epoch 8/100\n",
            "11610/11610 [==============================] - 1s 89us/sample - loss: 0.4554 - val_loss: 0.4799\n",
            "Epoch 9/100\n",
            "11610/11610 [==============================] - 1s 90us/sample - loss: 0.4476 - val_loss: 0.4671\n",
            "Epoch 10/100\n",
            "11610/11610 [==============================] - 1s 91us/sample - loss: 0.4412 - val_loss: 0.4599\n",
            "Epoch 11/100\n",
            "11610/11610 [==============================] - 1s 88us/sample - loss: 0.4366 - val_loss: 0.4535\n",
            "Epoch 12/100\n",
            "11610/11610 [==============================] - 1s 86us/sample - loss: 0.4294 - val_loss: 0.4500\n",
            "Epoch 13/100\n",
            "11610/11610 [==============================] - 1s 89us/sample - loss: 0.4259 - val_loss: 0.4435\n",
            "Epoch 14/100\n",
            "11610/11610 [==============================] - 1s 90us/sample - loss: 0.4219 - val_loss: 0.4385\n",
            "Epoch 15/100\n",
            "11610/11610 [==============================] - 1s 98us/sample - loss: 0.4167 - val_loss: 0.4347\n",
            "Epoch 16/100\n",
            "11610/11610 [==============================] - 1s 85us/sample - loss: 0.4136 - val_loss: 0.4309\n",
            "Epoch 17/100\n",
            "11610/11610 [==============================] - 1s 87us/sample - loss: 0.4090 - val_loss: 0.4268\n",
            "Epoch 18/100\n",
            "11610/11610 [==============================] - 1s 86us/sample - loss: 0.4080 - val_loss: 0.4234\n",
            "Epoch 19/100\n",
            "11610/11610 [==============================] - 1s 103us/sample - loss: 0.4035 - val_loss: 0.4198\n",
            "Epoch 20/100\n",
            "11610/11610 [==============================] - 1s 84us/sample - loss: 0.4000 - val_loss: 0.4176\n",
            "Epoch 21/100\n",
            "11610/11610 [==============================] - 1s 92us/sample - loss: 0.3992 - val_loss: 0.4144\n",
            "Epoch 22/100\n",
            "11610/11610 [==============================] - 1s 95us/sample - loss: 0.3970 - val_loss: 0.4111\n",
            "Epoch 23/100\n",
            "11610/11610 [==============================] - 1s 92us/sample - loss: 0.3929 - val_loss: 0.4078\n",
            "Epoch 24/100\n",
            "11610/11610 [==============================] - 1s 95us/sample - loss: 0.3908 - val_loss: 0.4052\n",
            "Epoch 25/100\n",
            "11610/11610 [==============================] - 1s 89us/sample - loss: 0.3875 - val_loss: 0.4039\n",
            "Epoch 26/100\n",
            "11610/11610 [==============================] - 1s 90us/sample - loss: 0.3865 - val_loss: 0.4013\n",
            "Epoch 27/100\n",
            "11610/11610 [==============================] - 1s 85us/sample - loss: 0.3845 - val_loss: 0.4002\n",
            "Epoch 28/100\n",
            "11610/11610 [==============================] - 1s 88us/sample - loss: 0.3825 - val_loss: 0.3969\n",
            "Epoch 29/100\n",
            "11610/11610 [==============================] - 1s 86us/sample - loss: 0.3817 - val_loss: 0.3995\n",
            "Epoch 30/100\n",
            "11610/11610 [==============================] - 1s 92us/sample - loss: 0.3817 - val_loss: 0.3958\n",
            "Epoch 31/100\n",
            "11610/11610 [==============================] - 1s 87us/sample - loss: 0.3784 - val_loss: 0.3915\n",
            "Epoch 32/100\n",
            "11610/11610 [==============================] - 1s 86us/sample - loss: 0.3769 - val_loss: 0.3894\n",
            "Epoch 33/100\n",
            "11610/11610 [==============================] - 1s 87us/sample - loss: 0.3765 - val_loss: 0.3881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwKk-GsPNIvy",
        "colab_type": "code",
        "outputId": "753121a5-5084-48c8-a20e-1efca54c5ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "def plot_learning_curves(history):\n",
        "    pd.DataFrame(history.history).plot(figsize = (8,5))\n",
        "    plt.grid(True)\n",
        "    plt.gca().set_ylim(0,1)\n",
        "    plt.show()\n",
        "plot_learning_curves(history)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxiIiIh77/3+aT3kLbr51AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4WRdN_l2nks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd8094df-13e7-4fd4-aed2-bdbbfe4fc525"
      },
      "source": [
        "from scipy.stats import reciprocal\n",
        "reciprocal.rvs(1e-4, 1e-2, size=10).tolist()\n",
        "reciprocal(1e-4, 1e-2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<scipy.stats._distn_infrastructure.rv_frozen at 0x7f89b026aa20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDb6JUPovWli",
        "colab_type": "code",
        "outputId": "13ca329d-d87a-454d-b44b-a79c6ca09f3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from scipy.stats import reciprocal\n",
        "# f(x) = 1/(x*log(b/a)) a <= x <= b\n",
        "\n",
        "param_distribution = {\n",
        "    \"hidden_layers\":[1, 2, 3, 4],\n",
        "    #\"layer_size\": [1, 10, 100],\n",
        "    #\"learning_rate\": [1e-4, 1e-2]\n",
        "    \"layer_size\": np.arange(1, 100).tolist(),\n",
        "    \"learning_rate\": reciprocal.rvs(1e-4, 1e-2, size=10).tolist()\n",
        "}\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "#from sklearn.model_selection import GridSearchCV\n",
        "# n_iterint, default=10: Number of parameter settings that are sampled.\n",
        "# n_iter trades off runtime vs quality of the solution.\n",
        "# cv = 5 by defult (cross validate)\n",
        "# n_jobsint or None, optional (default=None): Number of jobs to run in parallel.\n",
        "# None means 1 unless in a joblib.parallel_backend context. -1 means using all processors.\n",
        "# See Glossary for more details.\n",
        "random_search_cv = RandomizedSearchCV(sklearn_model,\n",
        "                                      param_distribution,\n",
        "                                      cv = 3,\n",
        "                                      n_iter = 10,\n",
        "                                      n_jobs = 1)\n",
        "random_search_cv.fit(x_train_scaled, y_train, epochs = 100,\n",
        "                     validation_data = (x_valid_scaled, y_valid),\n",
        "                     callbacks = callbacks)\n",
        "# cross_validation: training data into n sets, n-1 for training for hp, 1 for validate\n",
        "# the final lost is based on all n traing data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 153us/sample - loss: 4.4286 - val_loss: 3.9796\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 3.2314 - val_loss: 2.8086\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 2.2786 - val_loss: 2.0072\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 1.6957 - val_loss: 1.5653\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 1.3881 - val_loss: 1.3339\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 1.2215 - val_loss: 1.1975\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 1.1139 - val_loss: 1.1027\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 1.0343 - val_loss: 1.0301\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.9715 - val_loss: 0.9731\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.9214 - val_loss: 0.9271\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.8801 - val_loss: 0.8892\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.8456 - val_loss: 0.8576\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.8166 - val_loss: 0.8309\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.7919 - val_loss: 0.8082\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.7707 - val_loss: 0.7890\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.7527 - val_loss: 0.7722\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.7369 - val_loss: 0.7573\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.7232 - val_loss: 0.7441\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.7109 - val_loss: 0.7325\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.7000 - val_loss: 0.7222\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.6902 - val_loss: 0.7130\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.6814 - val_loss: 0.7046\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.6733 - val_loss: 0.6970\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 124us/sample - loss: 0.6660 - val_loss: 0.6900\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.6592 - val_loss: 0.6835\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.6529 - val_loss: 0.6775\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.6470 - val_loss: 0.6718\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.6415 - val_loss: 0.6665\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.6364 - val_loss: 0.6614\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.6314 - val_loss: 0.6566\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.6267 - val_loss: 0.6520\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.6223 - val_loss: 0.6475\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.6182 - val_loss: 0.6433\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.6141 - val_loss: 0.6392\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.6104 - val_loss: 0.6354\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.6066 - val_loss: 0.6317\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 132us/sample - loss: 0.6030 - val_loss: 0.6280\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5996 - val_loss: 0.6243\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5962 - val_loss: 0.6208\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.5929 - val_loss: 0.6174\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.5897 - val_loss: 0.6141\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.5866 - val_loss: 0.6109\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.5835 - val_loss: 0.6078\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5805 - val_loss: 0.6045\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.5776 - val_loss: 0.6014\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5748 - val_loss: 0.5985\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.5719 - val_loss: 0.5956\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.5693 - val_loss: 0.5926\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.5666 - val_loss: 0.5899\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.5640 - val_loss: 0.5870\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 0.5613 - val_loss: 0.5843\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 1s 125us/sample - loss: 0.5588 - val_loss: 0.5817\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.5564 - val_loss: 0.5790\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 0.5540 - val_loss: 0.5765\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.5516 - val_loss: 0.5740\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5494 - val_loss: 0.5715\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.5471 - val_loss: 0.5691\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.5449 - val_loss: 0.5667\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.5427 - val_loss: 0.5644\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.5406 - val_loss: 0.5620\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.5384 - val_loss: 0.5598\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.5364 - val_loss: 0.5575\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.5343 - val_loss: 0.5554\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.5324 - val_loss: 0.5533\n",
            "Epoch 65/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.5304 - val_loss: 0.5511\n",
            "Epoch 66/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.5285 - val_loss: 0.5489\n",
            "Epoch 67/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.5265 - val_loss: 0.5469\n",
            "Epoch 68/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.5247 - val_loss: 0.5449\n",
            "Epoch 69/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.5228 - val_loss: 0.5429\n",
            "Epoch 70/100\n",
            "7740/7740 [==============================] - 1s 127us/sample - loss: 0.5210 - val_loss: 0.5410\n",
            "Epoch 71/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5192 - val_loss: 0.5392\n",
            "3870/3870 [==============================] - 0s 57us/sample - loss: 0.4812\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 156us/sample - loss: 5.3147 - val_loss: 5.3539\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 4.9320 - val_loss: 4.9822\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 4.5859 - val_loss: 4.6455\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 4.2729 - val_loss: 4.3408\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 122us/sample - loss: 3.9898 - val_loss: 4.0648\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 3.7337 - val_loss: 3.8148\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 3.5022 - val_loss: 3.5885\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 3.2927 - val_loss: 3.3834\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 3.1033 - val_loss: 3.1976\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 2.9319 - val_loss: 3.0294\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 2.7769 - val_loss: 2.8769\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 2.6368 - val_loss: 2.7389\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 2.5100 - val_loss: 2.6137\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 2.3954 - val_loss: 2.5003\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 2.2917 - val_loss: 2.3976\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 2.1979 - val_loss: 2.3045\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 2.1131 - val_loss: 2.2200\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 2.0364 - val_loss: 2.1435\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 1.9670 - val_loss: 2.0742\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 1.9043 - val_loss: 2.0113\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 123us/sample - loss: 1.8475 - val_loss: 1.9542\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 1.7962 - val_loss: 1.9025\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 1.7498 - val_loss: 1.8555\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 1.7078 - val_loss: 1.8130\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 1.6698 - val_loss: 1.7743\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 121us/sample - loss: 1.6354 - val_loss: 1.7393\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 1.6044 - val_loss: 1.7074\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 1.5763 - val_loss: 1.6786\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 1.5509 - val_loss: 1.6523\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 1.5279 - val_loss: 1.6285\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 1.5071 - val_loss: 1.6069\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 1.4883 - val_loss: 1.5872\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 1.4713 - val_loss: 1.5693\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 127us/sample - loss: 1.4559 - val_loss: 1.5531\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 1.4420 - val_loss: 1.5384\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 1.4295 - val_loss: 1.5249\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 1.4181 - val_loss: 1.5127\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 1.4078 - val_loss: 1.5016\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 1.3985 - val_loss: 1.4915\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 1.3901 - val_loss: 1.4823\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 1.3824 - val_loss: 1.4739\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 1.3755 - val_loss: 1.4663\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 1.3693 - val_loss: 1.4593\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 1.3637 - val_loss: 1.4530\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 1.3586 - val_loss: 1.4472\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 1.3540 - val_loss: 1.4419\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 1.3498 - val_loss: 1.4371\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 1.3460 - val_loss: 1.4327\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 1s 136us/sample - loss: 1.3426 - val_loss: 1.4287\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 1.3395 - val_loss: 1.4251\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 1.3367 - val_loss: 1.4217\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 1.3342 - val_loss: 1.4187\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 1.3319 - val_loss: 1.4159\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 1.3299 - val_loss: 1.4134\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 1.3280 - val_loss: 1.4110\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 1.3263 - val_loss: 1.4089\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 1.3248 - val_loss: 1.4069\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 1.3234 - val_loss: 1.4051\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 1.3222 - val_loss: 1.4035\n",
            "3870/3870 [==============================] - 0s 49us/sample - loss: 1.3305\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 151us/sample - loss: 5.2861 - val_loss: 5.3553\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 4.9061 - val_loss: 4.9847\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 4.5623 - val_loss: 4.6491\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 4.2514 - val_loss: 4.3451\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 3.9703 - val_loss: 4.0698\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 3.7160 - val_loss: 3.8205\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 124us/sample - loss: 3.4860 - val_loss: 3.5946\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 3.2779 - val_loss: 3.3899\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 3.0898 - val_loss: 3.2045\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 2.9196 - val_loss: 3.0364\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 2.7657 - val_loss: 2.8842\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 2.6265 - val_loss: 2.7463\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 2.5006 - val_loss: 2.6212\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 2.3868 - val_loss: 2.5079\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 2.2838 - val_loss: 2.4051\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 2.1906 - val_loss: 2.3120\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 2.1064 - val_loss: 2.2275\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 2.0302 - val_loss: 2.1509\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 1.9613 - val_loss: 2.0814\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 1.8990 - val_loss: 2.0184\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 1.8426 - val_loss: 1.9612\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 1.7916 - val_loss: 1.9093\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 1.7455 - val_loss: 1.8622\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 1.7038 - val_loss: 1.8195\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 1.6661 - val_loss: 1.7806\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 1.6319 - val_loss: 1.7454\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 1.6011 - val_loss: 1.7134\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 1.5732 - val_loss: 1.6843\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 1.5479 - val_loss: 1.6579\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 1.5251 - val_loss: 1.6340\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 1.5045 - val_loss: 1.6122\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 1.4858 - val_loss: 1.5923\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 1.4689 - val_loss: 1.5743\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 1.4536 - val_loss: 1.5579\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 1.4398 - val_loss: 1.5430\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 1.4273 - val_loss: 1.5294\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 1.4160 - val_loss: 1.5170\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 1.4058 - val_loss: 1.5058\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 1.3965 - val_loss: 1.4955\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 1.3882 - val_loss: 1.4862\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 1.3806 - val_loss: 1.4777\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 1.3738 - val_loss: 1.4699\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 1s 136us/sample - loss: 1.3676 - val_loss: 1.4628\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 1.3620 - val_loss: 1.4564\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 1.3569 - val_loss: 1.4505\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 1.3523 - val_loss: 1.4451\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 1.3482 - val_loss: 1.4402\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 1s 123us/sample - loss: 1.3444 - val_loss: 1.4357\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 1.3411 - val_loss: 1.4316\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 1.3380 - val_loss: 1.4278\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 1.3352 - val_loss: 1.4244\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 1.3327 - val_loss: 1.4212\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 1.3305 - val_loss: 1.4184\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 1.3284 - val_loss: 1.4157\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 1.3265 - val_loss: 1.4133\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 1.3249 - val_loss: 1.4111\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 1s 122us/sample - loss: 1.3233 - val_loss: 1.4090\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 1s 125us/sample - loss: 1.3220 - val_loss: 1.4072\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 1.3207 - val_loss: 1.4055\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 1.3196 - val_loss: 1.4039\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 1.3186 - val_loss: 1.4024\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 1.3177 - val_loss: 1.4011\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 1.3168 - val_loss: 1.3999\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 1s 125us/sample - loss: 1.3161 - val_loss: 1.3987\n",
            "3870/3870 [==============================] - 0s 54us/sample - loss: 1.3324\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 146us/sample - loss: 2.6303 - val_loss: 1.2559\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 1.1386 - val_loss: 0.9456\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.8859 - val_loss: 0.8322\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.7814 - val_loss: 0.7703\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.7235 - val_loss: 0.7267\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.6834 - val_loss: 0.6960\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.6556 - val_loss: 0.6738\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.6338 - val_loss: 0.6554\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.6164 - val_loss: 0.6407\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.6016 - val_loss: 0.6259\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.5891 - val_loss: 0.6145\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 122us/sample - loss: 0.5776 - val_loss: 0.6052\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.5675 - val_loss: 0.5926\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.5584 - val_loss: 0.5835\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.5501 - val_loss: 0.5752\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.5424 - val_loss: 0.5683\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.5352 - val_loss: 0.5600\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.5288 - val_loss: 0.5537\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.5226 - val_loss: 0.5475\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.5171 - val_loss: 0.5425\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 0.5117 - val_loss: 0.5366\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 0.5070 - val_loss: 0.5326\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.5019 - val_loss: 0.5273\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.4980 - val_loss: 0.5228\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4939 - val_loss: 0.5187\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4899 - val_loss: 0.5145\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4863 - val_loss: 0.5107\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.4829 - val_loss: 0.5079\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.4796 - val_loss: 0.5044\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.4762 - val_loss: 0.5019\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4738 - val_loss: 0.4987\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.4710 - val_loss: 0.4956\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4682 - val_loss: 0.4926\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.4657 - val_loss: 0.4901\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.4634 - val_loss: 0.4874\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4611 - val_loss: 0.4854\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4587 - val_loss: 0.4830\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.4563 - val_loss: 0.4811\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.4547 - val_loss: 0.4782\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.4526 - val_loss: 0.4758\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.4506 - val_loss: 0.4745\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.4487 - val_loss: 0.4724\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4469 - val_loss: 0.4706\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4449 - val_loss: 0.4682\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.4435 - val_loss: 0.4666\n",
            "3870/3870 [==============================] - 0s 58us/sample - loss: 0.4137\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 143us/sample - loss: 3.0776 - val_loss: 1.7724\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 125us/sample - loss: 1.3255 - val_loss: 1.1008\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.9193 - val_loss: 0.8755\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.7745 - val_loss: 0.7861\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.7152 - val_loss: 0.7443\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.6849 - val_loss: 0.7183\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.6644 - val_loss: 0.6988\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.6479 - val_loss: 0.6821\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.6331 - val_loss: 0.6669\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.6196 - val_loss: 0.6527\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.6070 - val_loss: 0.6393\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.5948 - val_loss: 0.6264\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.5834 - val_loss: 0.6146\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.5727 - val_loss: 0.6031\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.5622 - val_loss: 0.5923\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.5525 - val_loss: 0.5828\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 131us/sample - loss: 0.5435 - val_loss: 0.5723\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5348 - val_loss: 0.5628\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.5269 - val_loss: 0.5543\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.5194 - val_loss: 0.5460\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.5125 - val_loss: 0.5386\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.5059 - val_loss: 0.5313\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.4995 - val_loss: 0.5245\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.4936 - val_loss: 0.5176\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4882 - val_loss: 0.5122\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.4831 - val_loss: 0.5066\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4782 - val_loss: 0.5015\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4739 - val_loss: 0.4968\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.4696 - val_loss: 0.4917\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4654 - val_loss: 0.4875\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.4619 - val_loss: 0.4833\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.4583 - val_loss: 0.4790\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4550 - val_loss: 0.4752\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4520 - val_loss: 0.4719\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.4493 - val_loss: 0.4688\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4461 - val_loss: 0.4653\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.4438 - val_loss: 0.4625\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.4412 - val_loss: 0.4597\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4389 - val_loss: 0.4570\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.4366 - val_loss: 0.4543\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4344 - val_loss: 0.4519\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.4323 - val_loss: 0.4499\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4302 - val_loss: 0.4481\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4281 - val_loss: 0.4463\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4267 - val_loss: 0.4434\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4247 - val_loss: 0.4418\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4232 - val_loss: 0.4396\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.4214 - val_loss: 0.4379\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4196 - val_loss: 0.4364\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4180 - val_loss: 0.4344\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.4166 - val_loss: 0.4334\n",
            "3870/3870 [==============================] - 0s 55us/sample - loss: 0.4165\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 143us/sample - loss: 2.6646 - val_loss: 1.3147\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 1.0486 - val_loss: 0.9243\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.7994 - val_loss: 0.8313\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.7401 - val_loss: 0.7812\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.7009 - val_loss: 0.7471\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.6714 - val_loss: 0.7190\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 124us/sample - loss: 0.6471 - val_loss: 0.6956\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.6266 - val_loss: 0.6758\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.6094 - val_loss: 0.6595\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.5944 - val_loss: 0.6451\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.5814 - val_loss: 0.6326\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.5701 - val_loss: 0.6214\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5600 - val_loss: 0.6111\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.5509 - val_loss: 0.6016\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.5426 - val_loss: 0.5932\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.5348 - val_loss: 0.5853\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.5279 - val_loss: 0.5776\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.5214 - val_loss: 0.5706\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5149 - val_loss: 0.5642\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 0.5093 - val_loss: 0.5578\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.5037 - val_loss: 0.5518\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4985 - val_loss: 0.5463\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4934 - val_loss: 0.5406\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4887 - val_loss: 0.5356\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4839 - val_loss: 0.5302\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4795 - val_loss: 0.5254\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.4752 - val_loss: 0.5203\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4711 - val_loss: 0.5161\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4669 - val_loss: 0.5120\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.4630 - val_loss: 0.5076\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.4593 - val_loss: 0.5030\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.4555 - val_loss: 0.4993\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4521 - val_loss: 0.4950\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.4486 - val_loss: 0.4913\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4451 - val_loss: 0.4877\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 128us/sample - loss: 0.4422 - val_loss: 0.4838\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4390 - val_loss: 0.4806\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.4360 - val_loss: 0.4777\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.4331 - val_loss: 0.4745\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4302 - val_loss: 0.4708\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4276 - val_loss: 0.4673\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4250 - val_loss: 0.4646\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.4226 - val_loss: 0.4624\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4201 - val_loss: 0.4597\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4177 - val_loss: 0.4580\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.4157 - val_loss: 0.4545\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4136 - val_loss: 0.4518\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.4113 - val_loss: 0.4492\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4093 - val_loss: 0.4468\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4071 - val_loss: 0.4472\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4056 - val_loss: 0.4433\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.4036 - val_loss: 0.4407\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.4019 - val_loss: 0.4389\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.4002 - val_loss: 0.4373\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.3982 - val_loss: 0.4350\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.3969 - val_loss: 0.4340\n",
            "3870/3870 [==============================] - 0s 59us/sample - loss: 0.4433\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 139us/sample - loss: 1.5099 - val_loss: 0.8021\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.6812 - val_loss: 0.6808\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.6104 - val_loss: 0.6246\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5704 - val_loss: 0.5847\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.5361 - val_loss: 0.5527\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5104 - val_loss: 0.5482\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.4884 - val_loss: 0.5045\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4706 - val_loss: 0.4859\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4556 - val_loss: 0.4704\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.4426 - val_loss: 0.4583\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4323 - val_loss: 0.4461\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.4217 - val_loss: 0.4353\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.4140 - val_loss: 0.4289\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4082 - val_loss: 0.4218\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4020 - val_loss: 0.4143\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.3956 - val_loss: 0.4094\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.3911 - val_loss: 0.4048\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.3876 - val_loss: 0.3979\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.3824 - val_loss: 0.3957\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.3788 - val_loss: 0.3920\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.3755 - val_loss: 0.3880\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 122us/sample - loss: 0.3719 - val_loss: 0.3841\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.3688 - val_loss: 0.3809\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.3647 - val_loss: 0.3784\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.3631 - val_loss: 0.3751\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.3607 - val_loss: 0.3716\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.3583 - val_loss: 0.3701\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.3540 - val_loss: 0.3763\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.3533 - val_loss: 0.3666\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.3509 - val_loss: 0.3659\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.3483 - val_loss: 0.3603\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.3465 - val_loss: 0.3588\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.3440 - val_loss: 0.3589\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.3417 - val_loss: 0.3588\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 135us/sample - loss: 0.3396 - val_loss: 0.3533\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.3384 - val_loss: 0.3573\n",
            "3870/3870 [==============================] - 0s 52us/sample - loss: 0.3374\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 138us/sample - loss: 1.1805 - val_loss: 0.7424\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.6314 - val_loss: 0.6508\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.5770 - val_loss: 0.6014\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5385 - val_loss: 0.5619\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.5087 - val_loss: 0.5319\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4829 - val_loss: 0.5048\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4627 - val_loss: 0.4846\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4463 - val_loss: 0.4626\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.4329 - val_loss: 0.4491\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.4220 - val_loss: 0.4379\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4128 - val_loss: 0.4295\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4066 - val_loss: 0.4190\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.3992 - val_loss: 0.4177\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 0.3948 - val_loss: 0.4081\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.3906 - val_loss: 0.4079\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.3867 - val_loss: 0.4001\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.3830 - val_loss: 0.3956\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.3802 - val_loss: 0.3951\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.3776 - val_loss: 0.3904\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.3746 - val_loss: 0.3873\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.3715 - val_loss: 0.3852\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.3701 - val_loss: 0.3842\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.3674 - val_loss: 0.3802\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.3656 - val_loss: 0.3785\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.3639 - val_loss: 0.3778\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.3625 - val_loss: 0.3775\n",
            "3870/3870 [==============================] - 0s 55us/sample - loss: 0.3571\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 144us/sample - loss: 1.2910 - val_loss: 0.7110\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5895 - val_loss: 0.6092\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.5265 - val_loss: 0.5615\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4921 - val_loss: 0.5277\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.4706 - val_loss: 0.5040\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4532 - val_loss: 0.4908\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.4395 - val_loss: 0.4726\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4273 - val_loss: 0.4609\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4184 - val_loss: 0.4510\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.4112 - val_loss: 0.4457\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.4042 - val_loss: 0.4366\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.3989 - val_loss: 0.4329\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.3933 - val_loss: 0.4274\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 122us/sample - loss: 0.3894 - val_loss: 0.4243\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.3840 - val_loss: 0.4205\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.3817 - val_loss: 0.4131\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.3781 - val_loss: 0.4136\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 123us/sample - loss: 0.3733 - val_loss: 0.4057\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.3707 - val_loss: 0.4053\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.3677 - val_loss: 0.4030\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.3660 - val_loss: 0.3978\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.3632 - val_loss: 0.3974\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.3598 - val_loss: 0.3982\n",
            "3870/3870 [==============================] - 0s 56us/sample - loss: 0.4086\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 135us/sample - loss: 1.4056 - val_loss: 0.7754\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.6770 - val_loss: 0.6787\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.6087 - val_loss: 0.6155\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.5599 - val_loss: 0.5695\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.5243 - val_loss: 0.5363\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4974 - val_loss: 0.5099\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.4775 - val_loss: 0.4940\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.4623 - val_loss: 0.4777\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4490 - val_loss: 0.4638\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 0.4390 - val_loss: 0.4550\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.4303 - val_loss: 0.4451\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4236 - val_loss: 0.4397\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4184 - val_loss: 0.4313\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4126 - val_loss: 0.4266\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.4081 - val_loss: 0.4189\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.4042 - val_loss: 0.4157\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.4004 - val_loss: 0.4117\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 125us/sample - loss: 0.3952 - val_loss: 0.4134\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.3932 - val_loss: 0.4028\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.3889 - val_loss: 0.4006\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.3866 - val_loss: 0.3991\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.3832 - val_loss: 0.3938\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.3810 - val_loss: 0.3910\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.3786 - val_loss: 0.3905\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.3766 - val_loss: 0.3869\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.3750 - val_loss: 0.3831\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.3723 - val_loss: 0.3857\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.3703 - val_loss: 0.3810\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.3692 - val_loss: 0.3840\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.3668 - val_loss: 0.3783\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.3648 - val_loss: 0.3842\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.3638 - val_loss: 0.3777\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 126us/sample - loss: 0.3619 - val_loss: 0.3725\n",
            "3870/3870 [==============================] - 0s 66us/sample - loss: 0.3546\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 142us/sample - loss: 1.4602 - val_loss: 0.7752\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.6355 - val_loss: 0.6348\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.5561 - val_loss: 0.5770\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5180 - val_loss: 0.5583\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4919 - val_loss: 0.5149\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.4727 - val_loss: 0.4947\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4557 - val_loss: 0.4770\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.4455 - val_loss: 0.4887\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4351 - val_loss: 0.4528\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4274 - val_loss: 0.4492\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4171 - val_loss: 0.4352\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.4105 - val_loss: 0.4278\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.4043 - val_loss: 0.4181\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.3998 - val_loss: 0.4465\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.3967 - val_loss: 0.4122\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.3918 - val_loss: 0.4102\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.3891 - val_loss: 0.4107\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.3870 - val_loss: 0.4024\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.3842 - val_loss: 0.4004\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.3821 - val_loss: 0.4016\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.3799 - val_loss: 0.3951\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.3782 - val_loss: 0.3937\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.3761 - val_loss: 0.3932\n",
            "3870/3870 [==============================] - 0s 54us/sample - loss: 0.3706\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 141us/sample - loss: 1.3526 - val_loss: 0.7303\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.6317 - val_loss: 0.6604\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.5803 - val_loss: 0.6190\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5434 - val_loss: 0.5793\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.5155 - val_loss: 0.5505\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4928 - val_loss: 0.5293\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4741 - val_loss: 0.5114\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4594 - val_loss: 0.4923\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4466 - val_loss: 0.4806\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.4350 - val_loss: 0.4678\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4267 - val_loss: 0.4603\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.4179 - val_loss: 0.4483\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4092 - val_loss: 0.4382\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.4027 - val_loss: 0.4329\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.3964 - val_loss: 0.4239\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.3908 - val_loss: 0.4201\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.3848 - val_loss: 0.4103\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.3808 - val_loss: 0.4049\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 126us/sample - loss: 0.3766 - val_loss: 0.4013\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.3735 - val_loss: 0.3981\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.3686 - val_loss: 0.3976\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.3664 - val_loss: 0.3912\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.3627 - val_loss: 0.3919\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.3598 - val_loss: 0.3846\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.3563 - val_loss: 0.3829\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.3536 - val_loss: 0.3789\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.3517 - val_loss: 0.3756\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.3485 - val_loss: 0.3786\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.3464 - val_loss: 0.3822\n",
            "3870/3870 [==============================] - 0s 54us/sample - loss: 0.3967\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 158us/sample - loss: 4.3940 - val_loss: 2.9078\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 134us/sample - loss: 1.9543 - val_loss: 1.4607\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 1.2277 - val_loss: 1.0912\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.9929 - val_loss: 0.9169\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.8516 - val_loss: 0.8117\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.7671 - val_loss: 0.7501\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.7160 - val_loss: 0.7125\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.6838 - val_loss: 0.6872\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.6609 - val_loss: 0.6679\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.6427 - val_loss: 0.6517\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.6274 - val_loss: 0.6374\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.6135 - val_loss: 0.6242\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.6011 - val_loss: 0.6119\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.5895 - val_loss: 0.6010\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.5790 - val_loss: 0.5907\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.5691 - val_loss: 0.5813\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 137us/sample - loss: 0.5600 - val_loss: 0.5726\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5515 - val_loss: 0.5644\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.5435 - val_loss: 0.5569\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.5359 - val_loss: 0.5498\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.5290 - val_loss: 0.5428\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.5220 - val_loss: 0.5365\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.5159 - val_loss: 0.5305\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.5098 - val_loss: 0.5248\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.5041 - val_loss: 0.5190\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4987 - val_loss: 0.5135\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.4935 - val_loss: 0.5085\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.4886 - val_loss: 0.5035\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4837 - val_loss: 0.4988\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4792 - val_loss: 0.4943\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.4746 - val_loss: 0.4902\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.4707 - val_loss: 0.4854\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4666 - val_loss: 0.4813\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 121us/sample - loss: 0.4627 - val_loss: 0.4775\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 124us/sample - loss: 0.4587 - val_loss: 0.4732\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.4551 - val_loss: 0.4696\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.4515 - val_loss: 0.4661\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 0.4482 - val_loss: 0.4629\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.4450 - val_loss: 0.4592\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4417 - val_loss: 0.4564\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.4386 - val_loss: 0.4530\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.4357 - val_loss: 0.4502\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4327 - val_loss: 0.4470\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4300 - val_loss: 0.4443\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4276 - val_loss: 0.4417\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 1s 121us/sample - loss: 0.4250 - val_loss: 0.4392\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 1s 130us/sample - loss: 0.4227 - val_loss: 0.4366\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.4205 - val_loss: 0.4347\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 1s 122us/sample - loss: 0.4184 - val_loss: 0.4322\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 1s 122us/sample - loss: 0.4162 - val_loss: 0.4307\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4142 - val_loss: 0.4284\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 1s 127us/sample - loss: 0.4124 - val_loss: 0.4263\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 1s 124us/sample - loss: 0.4105 - val_loss: 0.4244\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 1s 127us/sample - loss: 0.4087 - val_loss: 0.4224\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 1s 127us/sample - loss: 0.4069 - val_loss: 0.4207\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 1s 124us/sample - loss: 0.4052 - val_loss: 0.4191\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 1s 134us/sample - loss: 0.4034 - val_loss: 0.4179\n",
            "3870/3870 [==============================] - 0s 50us/sample - loss: 0.3809\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 170us/sample - loss: 3.3255 - val_loss: 1.8256\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 1.3147 - val_loss: 1.1356\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.9665 - val_loss: 0.9432\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.8397 - val_loss: 0.8514\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.7732 - val_loss: 0.8003\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.7306 - val_loss: 0.7655\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.6990 - val_loss: 0.7386\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.6734 - val_loss: 0.7166\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.6513 - val_loss: 0.6973\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.6322 - val_loss: 0.6804\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 127us/sample - loss: 0.6151 - val_loss: 0.6629\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 123us/sample - loss: 0.5990 - val_loss: 0.6477\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.5845 - val_loss: 0.6328\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.5711 - val_loss: 0.6187\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.5594 - val_loss: 0.6058\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.5479 - val_loss: 0.5943\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.5373 - val_loss: 0.5824\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.5275 - val_loss: 0.5718\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.5188 - val_loss: 0.5621\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5110 - val_loss: 0.5529\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 121us/sample - loss: 0.5034 - val_loss: 0.5447\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.4960 - val_loss: 0.5384\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4904 - val_loss: 0.5303\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4841 - val_loss: 0.5233\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4790 - val_loss: 0.5159\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 127us/sample - loss: 0.4739 - val_loss: 0.5099\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.4693 - val_loss: 0.5046\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 0.4651 - val_loss: 0.4994\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 122us/sample - loss: 0.4604 - val_loss: 0.4950\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.4572 - val_loss: 0.4901\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.4534 - val_loss: 0.4859\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 122us/sample - loss: 0.4498 - val_loss: 0.4826\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.4467 - val_loss: 0.4811\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.4440 - val_loss: 0.4754\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.4412 - val_loss: 0.4714\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 121us/sample - loss: 0.4383 - val_loss: 0.4687\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 0.4360 - val_loss: 0.4655\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4335 - val_loss: 0.4628\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4311 - val_loss: 0.4597\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.4285 - val_loss: 0.4585\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4265 - val_loss: 0.4549\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4246 - val_loss: 0.4522\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 1s 123us/sample - loss: 0.4223 - val_loss: 0.4508\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.4203 - val_loss: 0.4479\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.4186 - val_loss: 0.4454\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.4166 - val_loss: 0.4432\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4148 - val_loss: 0.4410\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4128 - val_loss: 0.4394\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4113 - val_loss: 0.4368\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.4094 - val_loss: 0.4346\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.4078 - val_loss: 0.4330\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 0.4061 - val_loss: 0.4306\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4047 - val_loss: 0.4290\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.4031 - val_loss: 0.4276\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.4017 - val_loss: 0.4257\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.3999 - val_loss: 0.4254\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.3982 - val_loss: 0.4228\n",
            "3870/3870 [==============================] - 0s 60us/sample - loss: 0.4022\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 150us/sample - loss: 2.7911 - val_loss: 1.5163\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 1.3095 - val_loss: 1.0411\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.9021 - val_loss: 0.8282\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.7369 - val_loss: 0.7318\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.6578 - val_loss: 0.6863\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 121us/sample - loss: 0.6159 - val_loss: 0.6593\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.5888 - val_loss: 0.6384\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 124us/sample - loss: 0.5678 - val_loss: 0.6198\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.5503 - val_loss: 0.6029\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.5346 - val_loss: 0.5871\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.5205 - val_loss: 0.5724\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.5074 - val_loss: 0.5587\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.4959 - val_loss: 0.5455\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4850 - val_loss: 0.5332\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.4750 - val_loss: 0.5222\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 0.4658 - val_loss: 0.5121\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4575 - val_loss: 0.5029\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.4497 - val_loss: 0.4941\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4426 - val_loss: 0.4858\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 122us/sample - loss: 0.4361 - val_loss: 0.4779\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 128us/sample - loss: 0.4302 - val_loss: 0.4720\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.4251 - val_loss: 0.4657\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.4201 - val_loss: 0.4598\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.4158 - val_loss: 0.4548\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4117 - val_loss: 0.4504\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.4080 - val_loss: 0.4461\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4048 - val_loss: 0.4422\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.4016 - val_loss: 0.4386\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.3985 - val_loss: 0.4359\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.3962 - val_loss: 0.4320\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 123us/sample - loss: 0.3928 - val_loss: 0.4312\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.3915 - val_loss: 0.4278\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.3894 - val_loss: 0.4236\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 121us/sample - loss: 0.3872 - val_loss: 0.4214\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 131us/sample - loss: 0.3852 - val_loss: 0.4191\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 128us/sample - loss: 0.3835 - val_loss: 0.4171\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.3816 - val_loss: 0.4172\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.3804 - val_loss: 0.4131\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.3787 - val_loss: 0.4116\n",
            "3870/3870 [==============================] - 0s 57us/sample - loss: 0.4236\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 150us/sample - loss: 1.0800 - val_loss: 0.6804\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.6866 - val_loss: 0.6163\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.5401 - val_loss: 0.5154\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.4764 - val_loss: 0.4685\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.4403 - val_loss: 0.4370\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4182 - val_loss: 0.4211\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.4025 - val_loss: 0.4174\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.3933 - val_loss: 0.3966\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.3842 - val_loss: 0.3874\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.3795 - val_loss: 0.3846\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.3747 - val_loss: 0.3798\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.3708 - val_loss: 0.3748\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.3660 - val_loss: 0.3737\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 123us/sample - loss: 0.3628 - val_loss: 0.3661\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.3581 - val_loss: 0.3716\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.3564 - val_loss: 0.3630\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.3523 - val_loss: 0.3679\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.3493 - val_loss: 0.3543\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.3470 - val_loss: 0.3602\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.3440 - val_loss: 0.3521\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.3396 - val_loss: 0.3515\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.3393 - val_loss: 0.3493\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.3360 - val_loss: 0.3526\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.3341 - val_loss: 0.3540\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.3305 - val_loss: 0.3431\n",
            "3870/3870 [==============================] - 0s 51us/sample - loss: 0.3319\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 146us/sample - loss: 1.1339 - val_loss: 0.6462\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.5294 - val_loss: 0.5212\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4672 - val_loss: 0.4756\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.4409 - val_loss: 0.4523\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4219 - val_loss: 0.4351\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4100 - val_loss: 0.4359\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.4043 - val_loss: 0.4187\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.3935 - val_loss: 0.4055\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.3851 - val_loss: 0.4017\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.3811 - val_loss: 0.3937\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.3752 - val_loss: 0.3895\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 124us/sample - loss: 0.3709 - val_loss: 0.3822\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.3669 - val_loss: 0.3803\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.3628 - val_loss: 0.3869\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.3594 - val_loss: 0.3825\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.3578 - val_loss: 0.3720\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.3521 - val_loss: 0.3713\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.3506 - val_loss: 0.3642\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.3479 - val_loss: 0.3648\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.3449 - val_loss: 0.3646\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.3436 - val_loss: 0.3582\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.3403 - val_loss: 0.3652\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.3374 - val_loss: 0.3542\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.3368 - val_loss: 0.3505\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 129us/sample - loss: 0.3347 - val_loss: 0.3540\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.3319 - val_loss: 0.3500\n",
            "3870/3870 [==============================] - 0s 50us/sample - loss: 0.3297\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 142us/sample - loss: 1.0872 - val_loss: 0.7122\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.6072 - val_loss: 0.6374\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.5466 - val_loss: 0.5970\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.5029 - val_loss: 0.5324\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4654 - val_loss: 0.4905\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.4324 - val_loss: 0.4633\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.4100 - val_loss: 0.4414\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.3939 - val_loss: 0.4250\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.3809 - val_loss: 0.4110\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.3708 - val_loss: 0.3974\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.3625 - val_loss: 0.4131\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.3559 - val_loss: 0.3828\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 130us/sample - loss: 0.3521 - val_loss: 0.3797\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.3479 - val_loss: 0.3824\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.3449 - val_loss: 0.3848\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.3407 - val_loss: 0.3680\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.3382 - val_loss: 0.3692\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.3345 - val_loss: 0.3698\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.3312 - val_loss: 0.3652\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.3274 - val_loss: 0.3639\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.3252 - val_loss: 0.3586\n",
            "3870/3870 [==============================] - 0s 57us/sample - loss: 0.3767\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 130us/sample - loss: 2.2932 - val_loss: 1.3742\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 90us/sample - loss: 1.0863 - val_loss: 0.8871\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.7817 - val_loss: 0.7853\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.7124 - val_loss: 0.7310\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.6688 - val_loss: 0.6925\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.6349 - val_loss: 0.6594\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.6087 - val_loss: 0.6376\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.5857 - val_loss: 0.6132\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.5674 - val_loss: 0.5941\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.5519 - val_loss: 0.5797\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.5384 - val_loss: 0.5677\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5274 - val_loss: 0.5535\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.5166 - val_loss: 0.5422\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.5088 - val_loss: 0.5341\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.5010 - val_loss: 0.5243\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.4927 - val_loss: 0.5287\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4874 - val_loss: 0.5123\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4807 - val_loss: 0.5031\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4758 - val_loss: 0.4967\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4705 - val_loss: 0.4926\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4651 - val_loss: 0.4879\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.4602 - val_loss: 0.4824\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4562 - val_loss: 0.4761\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4526 - val_loss: 0.4721\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4482 - val_loss: 0.4696\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4450 - val_loss: 0.4653\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.4422 - val_loss: 0.4616\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4387 - val_loss: 0.4585\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4361 - val_loss: 0.4544\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4334 - val_loss: 0.4514\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4303 - val_loss: 0.4489\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.4282 - val_loss: 0.4463\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.4261 - val_loss: 0.4441\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.4231 - val_loss: 0.4408\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.4217 - val_loss: 0.4386\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4195 - val_loss: 0.4367\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4174 - val_loss: 0.4340\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.4156 - val_loss: 0.4330\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4141 - val_loss: 0.4302\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4122 - val_loss: 0.4282\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.4106 - val_loss: 0.4261\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4088 - val_loss: 0.4245\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.4073 - val_loss: 0.4229\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4060 - val_loss: 0.4215\n",
            "3870/3870 [==============================] - 0s 53us/sample - loss: 0.3858\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 134us/sample - loss: 2.3722 - val_loss: 1.3635\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.9780 - val_loss: 0.8783\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.7806 - val_loss: 0.7927\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.7213 - val_loss: 0.7473\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 96us/sample - loss: 0.6810 - val_loss: 0.7115\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.6467 - val_loss: 0.6781\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.6169 - val_loss: 0.6491\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.5901 - val_loss: 0.6233\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.5663 - val_loss: 0.6006\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.5457 - val_loss: 0.5807\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.5281 - val_loss: 0.5634\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.5130 - val_loss: 0.5490\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.5010 - val_loss: 0.5367\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.4902 - val_loss: 0.5253\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4814 - val_loss: 0.5171\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4731 - val_loss: 0.5088\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.4664 - val_loss: 0.5009\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.4601 - val_loss: 0.4935\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.4549 - val_loss: 0.4913\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.4496 - val_loss: 0.4823\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4448 - val_loss: 0.4769\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4406 - val_loss: 0.4711\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.4362 - val_loss: 0.4670\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.4328 - val_loss: 0.4627\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.4290 - val_loss: 0.4587\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4260 - val_loss: 0.4545\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.4229 - val_loss: 0.4507\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.4198 - val_loss: 0.4479\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.4175 - val_loss: 0.4446\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.4149 - val_loss: 0.4418\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.4125 - val_loss: 0.4396\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.4102 - val_loss: 0.4363\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4079 - val_loss: 0.4344\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4062 - val_loss: 0.4314\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4044 - val_loss: 0.4294\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 94us/sample - loss: 0.4024 - val_loss: 0.4278\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4007 - val_loss: 0.4252\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.3989 - val_loss: 0.4239\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.3977 - val_loss: 0.4228\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.3961 - val_loss: 0.4198\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.3949 - val_loss: 0.4177\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.3931 - val_loss: 0.4171\n",
            "3870/3870 [==============================] - 0s 54us/sample - loss: 0.3978\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 142us/sample - loss: 2.3620 - val_loss: 1.4190\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 1.0165 - val_loss: 0.9265\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.7661 - val_loss: 0.7897\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.6904 - val_loss: 0.7400\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.6532 - val_loss: 0.7108\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.6275 - val_loss: 0.6875\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.6077 - val_loss: 0.6670\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.5907 - val_loss: 0.6494\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.5761 - val_loss: 0.6336\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.5633 - val_loss: 0.6202\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.5518 - val_loss: 0.6081\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5417 - val_loss: 0.5973\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.5323 - val_loss: 0.5865\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.5241 - val_loss: 0.5772\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.5167 - val_loss: 0.5691\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.5099 - val_loss: 0.5619\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.5035 - val_loss: 0.5547\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.4977 - val_loss: 0.5477\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4926 - val_loss: 0.5412\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4872 - val_loss: 0.5361\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.4827 - val_loss: 0.5306\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.4781 - val_loss: 0.5256\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.4741 - val_loss: 0.5202\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4701 - val_loss: 0.5165\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4661 - val_loss: 0.5121\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.4628 - val_loss: 0.5083\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.4594 - val_loss: 0.5032\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4561 - val_loss: 0.5006\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.4530 - val_loss: 0.4965\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.4497 - val_loss: 0.4932\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4468 - val_loss: 0.4902\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4441 - val_loss: 0.4870\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4408 - val_loss: 0.4824\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 121us/sample - loss: 0.4384 - val_loss: 0.4812\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.4357 - val_loss: 0.4774\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.4334 - val_loss: 0.4738\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4309 - val_loss: 0.4718\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.4285 - val_loss: 0.4686\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.4262 - val_loss: 0.4668\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4241 - val_loss: 0.4640\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.4216 - val_loss: 0.4615\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4194 - val_loss: 0.4594\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4176 - val_loss: 0.4560\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.4153 - val_loss: 0.4545\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4134 - val_loss: 0.4523\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4115 - val_loss: 0.4511\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.4094 - val_loss: 0.4490\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.4079 - val_loss: 0.4459\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4059 - val_loss: 0.4448\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 1s 127us/sample - loss: 0.4043 - val_loss: 0.4421\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.4025 - val_loss: 0.4404\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4007 - val_loss: 0.4395\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.3991 - val_loss: 0.4364\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.3973 - val_loss: 0.4348\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.3958 - val_loss: 0.4335\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.3941 - val_loss: 0.4324\n",
            "3870/3870 [==============================] - 0s 49us/sample - loss: 0.4380\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 133us/sample - loss: 3.6528 - val_loss: 3.3365\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 2.8558 - val_loss: 2.6591\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 2.3157 - val_loss: 2.1987\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 1.9479 - val_loss: 1.8800\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 1.6873 - val_loss: 1.6514\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 1.4967 - val_loss: 1.4822\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 1.3548 - val_loss: 1.3522\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 1.2447 - val_loss: 1.2527\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 1.1596 - val_loss: 1.1747\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 1.0916 - val_loss: 1.1121\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 1.0369 - val_loss: 1.0612\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.9918 - val_loss: 1.0196\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.9547 - val_loss: 0.9853\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.9241 - val_loss: 0.9568\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.8984 - val_loss: 0.9331\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.8768 - val_loss: 0.9128\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.8583 - val_loss: 0.8955\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.8424 - val_loss: 0.8806\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.8286 - val_loss: 0.8677\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.8166 - val_loss: 0.8563\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.8061 - val_loss: 0.8460\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 96us/sample - loss: 0.7966 - val_loss: 0.8368\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.7881 - val_loss: 0.8285\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 0.7803 - val_loss: 0.8209\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.7733 - val_loss: 0.8139\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.7667 - val_loss: 0.8075\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.7606 - val_loss: 0.8013\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.7549 - val_loss: 0.7955\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.7495 - val_loss: 0.7900\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.7444 - val_loss: 0.7847\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.7395 - val_loss: 0.7797\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.7348 - val_loss: 0.7748\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.7304 - val_loss: 0.7701\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.7260 - val_loss: 0.7656\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.7218 - val_loss: 0.7612\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.7178 - val_loss: 0.7570\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.7139 - val_loss: 0.7529\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 123us/sample - loss: 0.7100 - val_loss: 0.7489\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.7063 - val_loss: 0.7450\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.7027 - val_loss: 0.7411\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.6992 - val_loss: 0.7375\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.6958 - val_loss: 0.7338\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.6924 - val_loss: 0.7303\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.6891 - val_loss: 0.7267\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 0.6859 - val_loss: 0.7233\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.6827 - val_loss: 0.7199\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.6796 - val_loss: 0.7167\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.6765 - val_loss: 0.7135\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.6736 - val_loss: 0.7103\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 1s 122us/sample - loss: 0.6706 - val_loss: 0.7072\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 1s 131us/sample - loss: 0.6677 - val_loss: 0.7041\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.6649 - val_loss: 0.7011\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.6621 - val_loss: 0.6981\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.6594 - val_loss: 0.6952\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.6567 - val_loss: 0.6923\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.6540 - val_loss: 0.6895\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.6514 - val_loss: 0.6868\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.6488 - val_loss: 0.6840\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.6462 - val_loss: 0.6813\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.6437 - val_loss: 0.6786\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.6413 - val_loss: 0.6760\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.6388 - val_loss: 0.6733\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.6364 - val_loss: 0.6707\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 0.6340 - val_loss: 0.6681\n",
            "Epoch 65/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.6317 - val_loss: 0.6656\n",
            "Epoch 66/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.6293 - val_loss: 0.6632\n",
            "Epoch 67/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.6271 - val_loss: 0.6607\n",
            "Epoch 68/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.6248 - val_loss: 0.6584\n",
            "Epoch 69/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.6225 - val_loss: 0.6560\n",
            "Epoch 70/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.6203 - val_loss: 0.6536\n",
            "Epoch 71/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.6181 - val_loss: 0.6513\n",
            "Epoch 72/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.6159 - val_loss: 0.6489\n",
            "Epoch 73/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.6137 - val_loss: 0.6466\n",
            "Epoch 74/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.6116 - val_loss: 0.6443\n",
            "Epoch 75/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.6095 - val_loss: 0.6421\n",
            "Epoch 76/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.6074 - val_loss: 0.6399\n",
            "Epoch 77/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.6053 - val_loss: 0.6376\n",
            "Epoch 78/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.6033 - val_loss: 0.6354\n",
            "Epoch 79/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.6012 - val_loss: 0.6333\n",
            "Epoch 80/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5992 - val_loss: 0.6311\n",
            "Epoch 81/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.5972 - val_loss: 0.6289\n",
            "Epoch 82/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.5952 - val_loss: 0.6268\n",
            "Epoch 83/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5933 - val_loss: 0.6247\n",
            "Epoch 84/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.5913 - val_loss: 0.6226\n",
            "Epoch 85/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5894 - val_loss: 0.6205\n",
            "Epoch 86/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5875 - val_loss: 0.6185\n",
            "Epoch 87/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.5856 - val_loss: 0.6165\n",
            "Epoch 88/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5838 - val_loss: 0.6145\n",
            "Epoch 89/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.5819 - val_loss: 0.6124\n",
            "Epoch 90/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.5801 - val_loss: 0.6105\n",
            "Epoch 91/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.5783 - val_loss: 0.6085\n",
            "Epoch 92/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.5765 - val_loss: 0.6065\n",
            "Epoch 93/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.5747 - val_loss: 0.6046\n",
            "Epoch 94/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5729 - val_loss: 0.6026\n",
            "Epoch 95/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 0.5711 - val_loss: 0.6007\n",
            "Epoch 96/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.5694 - val_loss: 0.5988\n",
            "3870/3870 [==============================] - 0s 50us/sample - loss: 0.5286\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 125us/sample - loss: 3.8602 - val_loss: 3.4147\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 2.8781 - val_loss: 2.5810\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 2.2423 - val_loss: 2.0565\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 1.8306 - val_loss: 1.7249\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 1.5551 - val_loss: 1.4990\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 1.3636 - val_loss: 1.3417\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 1.2266 - val_loss: 1.2300\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 1.1244 - val_loss: 1.1437\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 1.0456 - val_loss: 1.0780\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.9844 - val_loss: 1.0263\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.9358 - val_loss: 0.9858\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.8973 - val_loss: 0.9525\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 0.8659 - val_loss: 0.9247\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.8401 - val_loss: 0.9013\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.8184 - val_loss: 0.8814\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.7999 - val_loss: 0.8644\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 0.7842 - val_loss: 0.8496\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.7706 - val_loss: 0.8364\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.7586 - val_loss: 0.8243\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.7479 - val_loss: 0.8135\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.7382 - val_loss: 0.8035\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.7294 - val_loss: 0.7944\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.7213 - val_loss: 0.7858\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.7137 - val_loss: 0.7777\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 96us/sample - loss: 0.7066 - val_loss: 0.7701\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.7000 - val_loss: 0.7629\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.6938 - val_loss: 0.7560\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 127us/sample - loss: 0.6879 - val_loss: 0.7495\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.6822 - val_loss: 0.7432\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.6768 - val_loss: 0.7373\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.6717 - val_loss: 0.7314\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.6668 - val_loss: 0.7259\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.6621 - val_loss: 0.7206\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.6575 - val_loss: 0.7154\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 96us/sample - loss: 0.6531 - val_loss: 0.7104\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.6489 - val_loss: 0.7056\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.6448 - val_loss: 0.7009\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.6408 - val_loss: 0.6963\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.6369 - val_loss: 0.6920\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.6332 - val_loss: 0.6876\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.6295 - val_loss: 0.6834\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.6260 - val_loss: 0.6794\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.6225 - val_loss: 0.6753\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 1s 127us/sample - loss: 0.6191 - val_loss: 0.6715\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.6158 - val_loss: 0.6677\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.6126 - val_loss: 0.6640\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.6094 - val_loss: 0.6604\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.6063 - val_loss: 0.6568\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.6033 - val_loss: 0.6534\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.6004 - val_loss: 0.6499\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5975 - val_loss: 0.6466\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.5947 - val_loss: 0.6434\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.5919 - val_loss: 0.6403\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.5892 - val_loss: 0.6372\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.5865 - val_loss: 0.6342\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 1s 96us/sample - loss: 0.5839 - val_loss: 0.6311\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5813 - val_loss: 0.6282\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.5788 - val_loss: 0.6253\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.5763 - val_loss: 0.6225\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 0.5738 - val_loss: 0.6196\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.5714 - val_loss: 0.6169\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.5691 - val_loss: 0.6142\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.5667 - val_loss: 0.6116\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.5644 - val_loss: 0.6091\n",
            "Epoch 65/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.5621 - val_loss: 0.6064\n",
            "Epoch 66/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.5599 - val_loss: 0.6039\n",
            "Epoch 67/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.5577 - val_loss: 0.6014\n",
            "Epoch 68/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5556 - val_loss: 0.5989\n",
            "Epoch 69/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.5535 - val_loss: 0.5965\n",
            "Epoch 70/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.5514 - val_loss: 0.5941\n",
            "Epoch 71/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5493 - val_loss: 0.5919\n",
            "Epoch 72/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.5473 - val_loss: 0.5896\n",
            "Epoch 73/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.5453 - val_loss: 0.5874\n",
            "Epoch 74/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.5434 - val_loss: 0.5852\n",
            "Epoch 75/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.5414 - val_loss: 0.5830\n",
            "Epoch 76/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.5395 - val_loss: 0.5809\n",
            "Epoch 77/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.5377 - val_loss: 0.5789\n",
            "Epoch 78/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.5358 - val_loss: 0.5769\n",
            "Epoch 79/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.5340 - val_loss: 0.5748\n",
            "Epoch 80/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5322 - val_loss: 0.5728\n",
            "Epoch 81/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.5305 - val_loss: 0.5708\n",
            "Epoch 82/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.5287 - val_loss: 0.5689\n",
            "Epoch 83/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5270 - val_loss: 0.5670\n",
            "Epoch 84/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.5254 - val_loss: 0.5651\n",
            "Epoch 85/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.5237 - val_loss: 0.5632\n",
            "Epoch 86/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.5221 - val_loss: 0.5615\n",
            "3870/3870 [==============================] - 0s 53us/sample - loss: 0.5320\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 129us/sample - loss: 4.3125 - val_loss: 3.8474\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 3.0372 - val_loss: 2.8408\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 2.2336 - val_loss: 2.1996\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 1.7348 - val_loss: 1.7940\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 1.4242 - val_loss: 1.5310\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 96us/sample - loss: 1.2269 - val_loss: 1.3529\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 1.0963 - val_loss: 1.2267\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 1.0059 - val_loss: 1.1331\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.9397 - val_loss: 1.0607\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.8895 - val_loss: 1.0039\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.8500 - val_loss: 0.9591\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.8181 - val_loss: 0.9224\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.7921 - val_loss: 0.8921\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.7705 - val_loss: 0.8668\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 123us/sample - loss: 0.7525 - val_loss: 0.8458\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 0.7374 - val_loss: 0.8281\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.7245 - val_loss: 0.8131\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.7134 - val_loss: 0.8000\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.7039 - val_loss: 0.7889\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.6954 - val_loss: 0.7791\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.6881 - val_loss: 0.7706\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.6814 - val_loss: 0.7630\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.6755 - val_loss: 0.7562\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.6701 - val_loss: 0.7500\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.6651 - val_loss: 0.7444\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.6605 - val_loss: 0.7390\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.6562 - val_loss: 0.7341\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.6521 - val_loss: 0.7295\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.6482 - val_loss: 0.7252\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.6445 - val_loss: 0.7210\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 122us/sample - loss: 0.6410 - val_loss: 0.7171\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.6376 - val_loss: 0.7132\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.6344 - val_loss: 0.7095\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.6312 - val_loss: 0.7060\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.6282 - val_loss: 0.7025\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.6252 - val_loss: 0.6992\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.6223 - val_loss: 0.6959\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.6195 - val_loss: 0.6927\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.6168 - val_loss: 0.6896\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.6140 - val_loss: 0.6865\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.6114 - val_loss: 0.6835\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 0.6088 - val_loss: 0.6805\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.6062 - val_loss: 0.6776\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.6037 - val_loss: 0.6748\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.6012 - val_loss: 0.6720\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.5988 - val_loss: 0.6692\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.5964 - val_loss: 0.6665\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 1s 94us/sample - loss: 0.5941 - val_loss: 0.6639\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.5918 - val_loss: 0.6612\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.5895 - val_loss: 0.6587\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.5872 - val_loss: 0.6561\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.5850 - val_loss: 0.6536\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5829 - val_loss: 0.6511\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5807 - val_loss: 0.6487\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.5786 - val_loss: 0.6463\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.5765 - val_loss: 0.6439\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.5745 - val_loss: 0.6416\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.5724 - val_loss: 0.6393\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 1s 96us/sample - loss: 0.5704 - val_loss: 0.6371\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.5684 - val_loss: 0.6349\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.5665 - val_loss: 0.6327\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.5645 - val_loss: 0.6305\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5626 - val_loss: 0.6283\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5607 - val_loss: 0.6262\n",
            "Epoch 65/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5589 - val_loss: 0.6241\n",
            "Epoch 66/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.5570 - val_loss: 0.6221\n",
            "Epoch 67/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.5552 - val_loss: 0.6200\n",
            "Epoch 68/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.5534 - val_loss: 0.6180\n",
            "Epoch 69/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.5517 - val_loss: 0.6160\n",
            "Epoch 70/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.5499 - val_loss: 0.6141\n",
            "Epoch 71/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.5482 - val_loss: 0.6121\n",
            "Epoch 72/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5465 - val_loss: 0.6102\n",
            "3870/3870 [==============================] - 0s 53us/sample - loss: 0.5943\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 165us/sample - loss: 2.6361 - val_loss: 1.5944\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 1.0942 - val_loss: 0.9746\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.7960 - val_loss: 0.8122\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.7088 - val_loss: 0.7476\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.6708 - val_loss: 0.7091\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.6476 - val_loss: 0.6853\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.6302 - val_loss: 0.6654\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.6153 - val_loss: 0.6493\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 0.6027 - val_loss: 0.6352\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.5914 - val_loss: 0.6229\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.5814 - val_loss: 0.6119\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.5722 - val_loss: 0.6022\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 92us/sample - loss: 0.5638 - val_loss: 0.5932\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 91us/sample - loss: 0.5562 - val_loss: 0.5852\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5493 - val_loss: 0.5773\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.5427 - val_loss: 0.5704\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.5367 - val_loss: 0.5641\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.5312 - val_loss: 0.5581\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 0.5260 - val_loss: 0.5524\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 0.5212 - val_loss: 0.5475\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 92us/sample - loss: 0.5168 - val_loss: 0.5425\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.5125 - val_loss: 0.5383\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.5086 - val_loss: 0.5340\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.5050 - val_loss: 0.5300\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 94us/sample - loss: 0.5014 - val_loss: 0.5259\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 0.4982 - val_loss: 0.5220\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.4949 - val_loss: 0.5190\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 94us/sample - loss: 0.4922 - val_loss: 0.5157\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4893 - val_loss: 0.5126\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.4867 - val_loss: 0.5096\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.4840 - val_loss: 0.5072\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.4817 - val_loss: 0.5043\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.4796 - val_loss: 0.5018\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4774 - val_loss: 0.4996\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.4754 - val_loss: 0.4974\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.4733 - val_loss: 0.4951\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.4717 - val_loss: 0.4932\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4698 - val_loss: 0.4911\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.4681 - val_loss: 0.4894\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 92us/sample - loss: 0.4666 - val_loss: 0.4875\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4651 - val_loss: 0.4858\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 0.4637 - val_loss: 0.4842\n",
            "3870/3870 [==============================] - 0s 61us/sample - loss: 0.4321\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 123us/sample - loss: 2.9308 - val_loss: 1.6535\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 93us/sample - loss: 1.2894 - val_loss: 1.0442\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 0.9354 - val_loss: 0.9108\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.8294 - val_loss: 0.8614\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.7826 - val_loss: 0.8328\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.7525 - val_loss: 0.8109\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 94us/sample - loss: 0.7289 - val_loss: 0.7912\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.7094 - val_loss: 0.7722\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.6919 - val_loss: 0.7548\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.6757 - val_loss: 0.7393\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.6618 - val_loss: 0.7240\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 0.6486 - val_loss: 0.7096\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.6364 - val_loss: 0.6968\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.6255 - val_loss: 0.6851\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 0.6151 - val_loss: 0.6738\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.6057 - val_loss: 0.6625\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.5965 - val_loss: 0.6524\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 96us/sample - loss: 0.5883 - val_loss: 0.6437\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.5806 - val_loss: 0.6346\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 96us/sample - loss: 0.5733 - val_loss: 0.6258\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.5662 - val_loss: 0.6179\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.5598 - val_loss: 0.6116\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.5541 - val_loss: 0.6046\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5481 - val_loss: 0.5974\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5429 - val_loss: 0.5915\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.5378 - val_loss: 0.5848\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 93us/sample - loss: 0.5326 - val_loss: 0.5802\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.5283 - val_loss: 0.5744\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.5240 - val_loss: 0.5683\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.5201 - val_loss: 0.5648\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5163 - val_loss: 0.5604\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.5127 - val_loss: 0.5557\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.5093 - val_loss: 0.5524\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5060 - val_loss: 0.5475\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5032 - val_loss: 0.5439\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5004 - val_loss: 0.5410\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.4976 - val_loss: 0.5381\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.4951 - val_loss: 0.5341\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.4924 - val_loss: 0.5311\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.4903 - val_loss: 0.5279\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.4880 - val_loss: 0.5258\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 93us/sample - loss: 0.4859 - val_loss: 0.5228\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4839 - val_loss: 0.5211\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.4818 - val_loss: 0.5192\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.4802 - val_loss: 0.5173\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.4784 - val_loss: 0.5145\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.4765 - val_loss: 0.5128\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 1s 96us/sample - loss: 0.4750 - val_loss: 0.5104\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.4734 - val_loss: 0.5091\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4718 - val_loss: 0.5079\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 1s 121us/sample - loss: 0.4704 - val_loss: 0.5059\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.4688 - val_loss: 0.5034\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.4674 - val_loss: 0.5020\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 1s 94us/sample - loss: 0.4661 - val_loss: 0.5004\n",
            "3870/3870 [==============================] - 0s 53us/sample - loss: 0.4703\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 125us/sample - loss: 2.9185 - val_loss: 1.7501\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 1.2396 - val_loss: 0.9930\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.8126 - val_loss: 0.8047\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.7033 - val_loss: 0.7511\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.6617 - val_loss: 0.7232\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.6378 - val_loss: 0.7033\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.6191 - val_loss: 0.6854\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.6033 - val_loss: 0.6695\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 96us/sample - loss: 0.5897 - val_loss: 0.6554\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.5773 - val_loss: 0.6426\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5667 - val_loss: 0.6310\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.5569 - val_loss: 0.6201\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.5481 - val_loss: 0.6100\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.5403 - val_loss: 0.6014\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.5331 - val_loss: 0.5931\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.5267 - val_loss: 0.5853\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.5208 - val_loss: 0.5783\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.5155 - val_loss: 0.5719\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 96us/sample - loss: 0.5105 - val_loss: 0.5663\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.5059 - val_loss: 0.5606\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.5018 - val_loss: 0.5557\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4979 - val_loss: 0.5513\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 96us/sample - loss: 0.4942 - val_loss: 0.5468\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.4908 - val_loss: 0.5425\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 0.4877 - val_loss: 0.5384\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.4849 - val_loss: 0.5345\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.4821 - val_loss: 0.5313\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 96us/sample - loss: 0.4795 - val_loss: 0.5280\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 0.4770 - val_loss: 0.5251\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.4747 - val_loss: 0.5221\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.4724 - val_loss: 0.5194\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4704 - val_loss: 0.5165\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4682 - val_loss: 0.5142\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.4664 - val_loss: 0.5116\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.4644 - val_loss: 0.5091\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 0.4627 - val_loss: 0.5069\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 94us/sample - loss: 0.4610 - val_loss: 0.5049\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.4592 - val_loss: 0.5027\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.4577 - val_loss: 0.5008\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.4561 - val_loss: 0.4987\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.4545 - val_loss: 0.4968\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 93us/sample - loss: 0.4530 - val_loss: 0.4952\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.4516 - val_loss: 0.4934\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 0.4501 - val_loss: 0.4920\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 1s 96us/sample - loss: 0.4488 - val_loss: 0.4903\n",
            "3870/3870 [==============================] - 0s 49us/sample - loss: 0.4833\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 155us/sample - loss: 4.8358 - val_loss: 4.1971\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 121us/sample - loss: 3.3546 - val_loss: 2.8837\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 2.2787 - val_loss: 1.9828\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 122us/sample - loss: 1.6384 - val_loss: 1.5168\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 1.3431 - val_loss: 1.3063\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 1.1941 - val_loss: 1.1826\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 1.0969 - val_loss: 1.0973\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 1.0249 - val_loss: 1.0289\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.9666 - val_loss: 0.9740\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.9185 - val_loss: 0.9289\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 124us/sample - loss: 0.8784 - val_loss: 0.8900\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.8443 - val_loss: 0.8576\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.8149 - val_loss: 0.8295\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.7895 - val_loss: 0.8055\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.7674 - val_loss: 0.7849\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.7482 - val_loss: 0.7669\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.7315 - val_loss: 0.7512\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.7169 - val_loss: 0.7375\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.7040 - val_loss: 0.7254\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.6925 - val_loss: 0.7148\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.6824 - val_loss: 0.7053\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.6734 - val_loss: 0.6969\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 124us/sample - loss: 0.6653 - val_loss: 0.6894\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 134us/sample - loss: 0.6581 - val_loss: 0.6826\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 124us/sample - loss: 0.6515 - val_loss: 0.6765\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.6455 - val_loss: 0.6708\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 121us/sample - loss: 0.6401 - val_loss: 0.6657\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.6350 - val_loss: 0.6611\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 122us/sample - loss: 0.6304 - val_loss: 0.6568\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.6262 - val_loss: 0.6525\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 126us/sample - loss: 0.6222 - val_loss: 0.6485\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.6184 - val_loss: 0.6450\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 121us/sample - loss: 0.6149 - val_loss: 0.6416\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 125us/sample - loss: 0.6115 - val_loss: 0.6382\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.6083 - val_loss: 0.6351\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.6053 - val_loss: 0.6320\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.6024 - val_loss: 0.6293\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 136us/sample - loss: 0.5997 - val_loss: 0.6265\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.5970 - val_loss: 0.6238\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 127us/sample - loss: 0.5945 - val_loss: 0.6212\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 122us/sample - loss: 0.5920 - val_loss: 0.6187\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.5896 - val_loss: 0.6162\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 1s 121us/sample - loss: 0.5873 - val_loss: 0.6139\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 1s 124us/sample - loss: 0.5850 - val_loss: 0.6117\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.5828 - val_loss: 0.6095\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.5807 - val_loss: 0.6073\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.5786 - val_loss: 0.6052\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.5765 - val_loss: 0.6030\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.5745 - val_loss: 0.6010\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.5725 - val_loss: 0.5989\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.5706 - val_loss: 0.5970\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5686 - val_loss: 0.5952\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.5668 - val_loss: 0.5933\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.5649 - val_loss: 0.5913\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 0.5631 - val_loss: 0.5895\n",
            "3870/3870 [==============================] - 0s 56us/sample - loss: 0.5192\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 145us/sample - loss: 4.1267 - val_loss: 3.5184\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 2.7857 - val_loss: 2.4471\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 2.0338 - val_loss: 1.8960\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 1.6562 - val_loss: 1.6047\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 1.4445 - val_loss: 1.4231\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 1.3014 - val_loss: 1.2932\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 1.1952 - val_loss: 1.1938\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 1.1097 - val_loss: 1.1137\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 121us/sample - loss: 1.0408 - val_loss: 1.0494\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.9837 - val_loss: 0.9966\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.9369 - val_loss: 0.9524\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 122us/sample - loss: 0.8977 - val_loss: 0.9163\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.8644 - val_loss: 0.8852\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.8364 - val_loss: 0.8596\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.8122 - val_loss: 0.8378\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.7916 - val_loss: 0.8196\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.7736 - val_loss: 0.8040\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.7582 - val_loss: 0.7903\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.7445 - val_loss: 0.7784\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.7324 - val_loss: 0.7678\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.7215 - val_loss: 0.7585\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.7116 - val_loss: 0.7500\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 121us/sample - loss: 0.7025 - val_loss: 0.7423\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.6942 - val_loss: 0.7351\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.6865 - val_loss: 0.7284\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.6793 - val_loss: 0.7221\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.6726 - val_loss: 0.7163\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 126us/sample - loss: 0.6663 - val_loss: 0.7107\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.6603 - val_loss: 0.7052\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.6545 - val_loss: 0.7001\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.6491 - val_loss: 0.6950\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 0.6437 - val_loss: 0.6900\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.6385 - val_loss: 0.6853\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.6334 - val_loss: 0.6807\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 123us/sample - loss: 0.6287 - val_loss: 0.6760\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 134us/sample - loss: 0.6240 - val_loss: 0.6715\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.6195 - val_loss: 0.6673\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.6152 - val_loss: 0.6630\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.6109 - val_loss: 0.6588\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.6068 - val_loss: 0.6550\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.6028 - val_loss: 0.6510\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5990 - val_loss: 0.6475\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5955 - val_loss: 0.6438\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.5919 - val_loss: 0.6402\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5884 - val_loss: 0.6369\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.5851 - val_loss: 0.6334\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.5819 - val_loss: 0.6301\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.5787 - val_loss: 0.6269\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 1s 103us/sample - loss: 0.5756 - val_loss: 0.6237\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 1s 127us/sample - loss: 0.5725 - val_loss: 0.6206\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 1s 130us/sample - loss: 0.5696 - val_loss: 0.6176\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.5668 - val_loss: 0.6146\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.5638 - val_loss: 0.6117\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.5612 - val_loss: 0.6089\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.5584 - val_loss: 0.6062\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.5558 - val_loss: 0.6033\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 1s 122us/sample - loss: 0.5533 - val_loss: 0.6006\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.5507 - val_loss: 0.5980\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.5483 - val_loss: 0.5955\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.5459 - val_loss: 0.5929\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5435 - val_loss: 0.5904\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.5412 - val_loss: 0.5880\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.5389 - val_loss: 0.5855\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.5368 - val_loss: 0.5832\n",
            "Epoch 65/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.5345 - val_loss: 0.5810\n",
            "Epoch 66/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5324 - val_loss: 0.5785\n",
            "Epoch 67/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5304 - val_loss: 0.5763\n",
            "Epoch 68/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.5284 - val_loss: 0.5741\n",
            "Epoch 69/100\n",
            "7740/7740 [==============================] - 1s 123us/sample - loss: 0.5263 - val_loss: 0.5720\n",
            "Epoch 70/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 0.5244 - val_loss: 0.5698\n",
            "Epoch 71/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.5225 - val_loss: 0.5677\n",
            "Epoch 72/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.5206 - val_loss: 0.5656\n",
            "Epoch 73/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.5187 - val_loss: 0.5635\n",
            "Epoch 74/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5169 - val_loss: 0.5615\n",
            "Epoch 75/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.5151 - val_loss: 0.5595\n",
            "Epoch 76/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 0.5134 - val_loss: 0.5575\n",
            "Epoch 77/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.5116 - val_loss: 0.5556\n",
            "Epoch 78/100\n",
            "7740/7740 [==============================] - 1s 121us/sample - loss: 0.5099 - val_loss: 0.5536\n",
            "3870/3870 [==============================] - 0s 51us/sample - loss: 0.5178\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 151us/sample - loss: 4.7714 - val_loss: 3.9766\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 3.0267 - val_loss: 2.5162\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 1.9087 - val_loss: 1.6607\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 1.3340 - val_loss: 1.2888\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 1.0909 - val_loss: 1.1246\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.9749 - val_loss: 1.0278\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.8978 - val_loss: 0.9564\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.8411 - val_loss: 0.9016\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.7977 - val_loss: 0.8591\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.7639 - val_loss: 0.8265\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.7374 - val_loss: 0.8012\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.7162 - val_loss: 0.7815\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.6991 - val_loss: 0.7654\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.6848 - val_loss: 0.7524\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.6726 - val_loss: 0.7410\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.6621 - val_loss: 0.7314\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.6527 - val_loss: 0.7232\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 123us/sample - loss: 0.6446 - val_loss: 0.7150\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.6370 - val_loss: 0.7077\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.6301 - val_loss: 0.7010\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.6236 - val_loss: 0.6946\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.6175 - val_loss: 0.6885\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.6117 - val_loss: 0.6825\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 1s 114us/sample - loss: 0.6060 - val_loss: 0.6771\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 0.6008 - val_loss: 0.6715\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 137us/sample - loss: 0.5956 - val_loss: 0.6658\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5907 - val_loss: 0.6606\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 1s 98us/sample - loss: 0.5859 - val_loss: 0.6558\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.5812 - val_loss: 0.6508\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5767 - val_loss: 0.6458\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.5724 - val_loss: 0.6411\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.5681 - val_loss: 0.6366\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.5639 - val_loss: 0.6319\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5599 - val_loss: 0.6275\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.5561 - val_loss: 0.6233\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5523 - val_loss: 0.6192\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.5486 - val_loss: 0.6152\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5450 - val_loss: 0.6111\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5415 - val_loss: 0.6072\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5381 - val_loss: 0.6033\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 1s 132us/sample - loss: 0.5347 - val_loss: 0.5995\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5315 - val_loss: 0.5958\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.5284 - val_loss: 0.5922\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.5253 - val_loss: 0.5887\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 1s 119us/sample - loss: 0.5223 - val_loss: 0.5853\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.5194 - val_loss: 0.5819\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.5166 - val_loss: 0.5786\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.5138 - val_loss: 0.5754\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 1s 113us/sample - loss: 0.5111 - val_loss: 0.5724\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.5085 - val_loss: 0.5695\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5060 - val_loss: 0.5664\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 1s 109us/sample - loss: 0.5034 - val_loss: 0.5635\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5010 - val_loss: 0.5607\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4986 - val_loss: 0.5580\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 0.4963 - val_loss: 0.5554\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4940 - val_loss: 0.5528\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4918 - val_loss: 0.5501\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 1s 101us/sample - loss: 0.4897 - val_loss: 0.5476\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 1s 120us/sample - loss: 0.4876 - val_loss: 0.5451\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4855 - val_loss: 0.5428\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.4835 - val_loss: 0.5404\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 1s 115us/sample - loss: 0.4815 - val_loss: 0.5381\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4796 - val_loss: 0.5359\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 1s 112us/sample - loss: 0.4778 - val_loss: 0.5337\n",
            "Epoch 65/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4760 - val_loss: 0.5316\n",
            "Epoch 66/100\n",
            "7740/7740 [==============================] - 1s 116us/sample - loss: 0.4742 - val_loss: 0.5295\n",
            "Epoch 67/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4725 - val_loss: 0.5275\n",
            "Epoch 68/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.4708 - val_loss: 0.5255\n",
            "Epoch 69/100\n",
            "7740/7740 [==============================] - 1s 108us/sample - loss: 0.4692 - val_loss: 0.5235\n",
            "Epoch 70/100\n",
            "7740/7740 [==============================] - 1s 104us/sample - loss: 0.4675 - val_loss: 0.5218\n",
            "Epoch 71/100\n",
            "7740/7740 [==============================] - 1s 117us/sample - loss: 0.4659 - val_loss: 0.5198\n",
            "Epoch 72/100\n",
            "7740/7740 [==============================] - 1s 111us/sample - loss: 0.4644 - val_loss: 0.5180\n",
            "3870/3870 [==============================] - 0s 61us/sample - loss: 0.5156\n",
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "11610/11610 [==============================] - 1s 118us/sample - loss: 1.0518 - val_loss: 0.5763\n",
            "Epoch 2/100\n",
            "11610/11610 [==============================] - 1s 102us/sample - loss: 0.4993 - val_loss: 0.5076\n",
            "Epoch 3/100\n",
            "11610/11610 [==============================] - 1s 91us/sample - loss: 0.4618 - val_loss: 0.4825\n",
            "Epoch 4/100\n",
            "11610/11610 [==============================] - 1s 94us/sample - loss: 0.4468 - val_loss: 0.4528\n",
            "Epoch 5/100\n",
            "11610/11610 [==============================] - 1s 95us/sample - loss: 0.4129 - val_loss: 0.4234\n",
            "Epoch 6/100\n",
            "11610/11610 [==============================] - 1s 96us/sample - loss: 0.4028 - val_loss: 0.4161\n",
            "Epoch 7/100\n",
            "11610/11610 [==============================] - 1s 102us/sample - loss: 0.4132 - val_loss: 0.4050\n",
            "Epoch 8/100\n",
            "11610/11610 [==============================] - 1s 109us/sample - loss: 0.3939 - val_loss: 0.3964\n",
            "Epoch 9/100\n",
            "11610/11610 [==============================] - 1s 99us/sample - loss: 0.3746 - val_loss: 0.3829\n",
            "Epoch 10/100\n",
            "11610/11610 [==============================] - 1s 100us/sample - loss: 0.3665 - val_loss: 0.3835\n",
            "Epoch 11/100\n",
            "11610/11610 [==============================] - 1s 105us/sample - loss: 0.3612 - val_loss: 0.3780\n",
            "Epoch 12/100\n",
            "11610/11610 [==============================] - 1s 99us/sample - loss: 0.3561 - val_loss: 0.3742\n",
            "Epoch 13/100\n",
            "11610/11610 [==============================] - 1s 99us/sample - loss: 0.3536 - val_loss: 0.3614\n",
            "Epoch 14/100\n",
            "11610/11610 [==============================] - 1s 96us/sample - loss: 0.3473 - val_loss: 0.3634\n",
            "Epoch 15/100\n",
            "11610/11610 [==============================] - 1s 97us/sample - loss: 0.3447 - val_loss: 0.3566\n",
            "Epoch 16/100\n",
            "11610/11610 [==============================] - 1s 99us/sample - loss: 0.3471 - val_loss: 0.3577\n",
            "Epoch 17/100\n",
            "11610/11610 [==============================] - 1s 110us/sample - loss: 0.3365 - val_loss: 0.3539\n",
            "Epoch 18/100\n",
            "11610/11610 [==============================] - 1s 97us/sample - loss: 0.3337 - val_loss: 0.3511\n",
            "Epoch 19/100\n",
            "11610/11610 [==============================] - 1s 96us/sample - loss: 0.3333 - val_loss: 0.3476\n",
            "Epoch 20/100\n",
            "11610/11610 [==============================] - 1s 104us/sample - loss: 0.3313 - val_loss: 0.3529\n",
            "Epoch 21/100\n",
            "11610/11610 [==============================] - 1s 102us/sample - loss: 0.3305 - val_loss: 0.3545\n",
            "Epoch 22/100\n",
            "11610/11610 [==============================] - 1s 91us/sample - loss: 0.3266 - val_loss: 0.3580\n",
            "Epoch 23/100\n",
            "11610/11610 [==============================] - 1s 93us/sample - loss: 0.3249 - val_loss: 0.3407\n",
            "Epoch 24/100\n",
            "11610/11610 [==============================] - 1s 91us/sample - loss: 0.3224 - val_loss: 0.3574\n",
            "Epoch 25/100\n",
            "11610/11610 [==============================] - 1s 105us/sample - loss: 0.3217 - val_loss: 0.3452\n",
            "Epoch 26/100\n",
            "11610/11610 [==============================] - 1s 97us/sample - loss: 0.3216 - val_loss: 0.3417\n",
            "Epoch 27/100\n",
            "11610/11610 [==============================] - 1s 98us/sample - loss: 0.3152 - val_loss: 0.3390\n",
            "Epoch 28/100\n",
            "11610/11610 [==============================] - 1s 110us/sample - loss: 0.3161 - val_loss: 0.3358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f89bd99cf28>,\n",
              "                   iid='deprecated', n_iter=10, n_jobs=1,\n",
              "                   param_distributions={'hidden_layers': [1, 2, 3, 4],\n",
              "                                        'layer_size': [1, 2, 3, 4, 5, 6, 7, 8,\n",
              "                                                       9, 10, 11, 12, 13, 14,\n",
              "                                                       15, 16, 17, 18, 19, 20,\n",
              "                                                       21, 22, 23, 24, 25, 26,\n",
              "                                                       27, 28, 29, 30, ...],\n",
              "                                        'learning_rate': [0.0005241509697928996,\n",
              "                                                          0.00010374152447233374,\n",
              "                                                          0.00015918406037185935,\n",
              "                                                          0.005281116851771535,\n",
              "                                                          0.002713758994645726,\n",
              "                                                          0.0004902281476265099,\n",
              "                                                          0.0010063590969242057,\n",
              "                                                          0.0006235636834029313,\n",
              "                                                          0.0011363554430375386,\n",
              "                                                          0.00011492130274199737]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtxDJ5pTwlHM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b91a6a4b-66ff-40c9-ac24-00210695ff5f"
      },
      "source": [
        "print(random_search_cv.best_params_)\n",
        "print(random_search_cv.best_score_)\n",
        "print(random_search_cv.best_estimator_)\n",
        "model = random_search_cv.best_estimator_.model\n",
        "model.evaluate(x_test_scaled, y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'learning_rate': 0.005281116851771535, 'layer_size': 64, 'hidden_layers': 3}\n",
            "-0.34608055587784164\n",
            "<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f89b0345898>\n",
            "5160/5160 [==============================] - 0s 67us/sample - loss: 0.3390\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3390093436536863"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}